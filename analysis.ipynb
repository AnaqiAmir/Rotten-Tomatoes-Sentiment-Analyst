{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixB_kwabKWsv"
   },
   "source": [
    "# Rotten Tomatoes Sentiment Analysis\n",
    "Conducting sentiment analysis (pos/neg) on the Rotten Tomatoes dataset from HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfJryXbOKWsx"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Gs5gcSB9KWsx"
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# WordCloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# HuggingFace\n",
    "import datasets\n",
    "\n",
    "# Transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Progress report\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDYYSHefKWsy"
   },
   "outputs": [],
   "source": [
    "# Setting seeds\n",
    "seed = 1234\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4y-QM9PLKWsz"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4pEaCGTKWsz",
    "outputId": "a311e9a5-bbde-4683-9e65-13cdb289544b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 8530\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 1066\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['text', 'label'],\n",
       "     num_rows: 1066\n",
       " }))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train, validation, and test data\n",
    "train_data, validation_data, test_data = datasets.load_dataset(\"rotten_tomatoes\",\n",
    "                                                               split=[\"train\", \"validation\", \"test\"])\n",
    "train_data, validation_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LuoF7E8xKWs0"
   },
   "outputs": [],
   "source": [
    "# Checking data example\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFQEEE9QKWs0"
   },
   "outputs": [],
   "source": [
    "# Data features\n",
    "train_data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "T0qWdeESKWs1",
    "outputId": "555695c6-3554-48fa-9ef0-7423e8d58620"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>8525</td>\n",
       "      <td>any enjoyment will be hinge from a personal th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>8526</td>\n",
       "      <td>if legendary shlockmeister ed wood had ever ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>8527</td>\n",
       "      <td>hardly a nuanced portrait of a young woman's b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>8528</td>\n",
       "      <td>interminably bleak , to say nothing of boring .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>8529</td>\n",
       "      <td>things really get weird , though not particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  label\n",
       "0        0  the rock is destined to be the 21st century's ...      1\n",
       "1        1  the gorgeously elaborate continuation of \" the...      1\n",
       "2        2                     effective but too-tepid biopic      1\n",
       "3        3  if you sometimes like to go to the movies to h...      1\n",
       "4        4  emerges as something rare , an issue movie tha...      1\n",
       "...    ...                                                ...    ...\n",
       "8525  8525  any enjoyment will be hinge from a personal th...      0\n",
       "8526  8526  if legendary shlockmeister ed wood had ever ma...      0\n",
       "8527  8527  hardly a nuanced portrait of a young woman's b...      0\n",
       "8528  8528    interminably bleak , to say nothing of boring .      0\n",
       "8529  8529  things really get weird , though not particula...      0\n",
       "\n",
       "[8530 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing train data into df form\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.rename(columns={'index':'id'}, inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9yHK0IaKWs1"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QR_j-mMGKWs1"
   },
   "outputs": [],
   "source": [
    "# Distribution between positive and negative reviews\n",
    "sns.countplot(data=train_df, x='label')\n",
    "plt.title(\"Distribution between pos/neg reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNcyX8aMKWs2"
   },
   "source": [
    "We can see that there is an equal distribution between movies that have positive reviews and movies that have negative reviews in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVsT50z-KWs2"
   },
   "outputs": [],
   "source": [
    "# Combine all text from the single column into one string\n",
    "text = \" \".join(train_df['text'].astype(str))\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccCkhKoXKWs2"
   },
   "source": [
    "## NLTK\n",
    "We will use the NLTK library to conduct sentiment analysis. Specifically, we will be using the Valence Aware Dictionary and sEntiment Reasoner (VADER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyzQ9YcnKWs2"
   },
   "outputs": [],
   "source": [
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Create instance of Sentiment Intensity Analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Example\n",
    "sia.polarity_scores(\"I am so happy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqRAtqr-KWs3"
   },
   "outputs": [],
   "source": [
    "# Another example\n",
    "sia.polarity_scores(\"I am so sad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EiQmmBPAKWs4"
   },
   "outputs": [],
   "source": [
    "# Applying polarity scores to the entire train_df\n",
    "results = {}\n",
    "for index, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    text = row['text']\n",
    "    myid = row['id']\n",
    "    results[myid] = sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jyKY3puuKWs4"
   },
   "outputs": [],
   "source": [
    "# Displaying the result in a dataframe format\n",
    "vaders = pd.DataFrame(results).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'id'})\n",
    "vaders = vaders.merge(train_df, how='inner', left_on='id', right_on='id')\n",
    "vaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcLTaeFQKWs5"
   },
   "outputs": [],
   "source": [
    "# Visualize results based on different sentiments\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3))\n",
    "sns.barplot(data=vaders, x='label', y='pos', ax=axs[0])\n",
    "sns.barplot(data=vaders, x='label', y='neu', ax=axs[1])\n",
    "sns.barplot(data=vaders, x='label', y='neg', ax=axs[2])\n",
    "sns.barplot(data=vaders, x='label', y='compound', ax=axs[3])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Neutral')\n",
    "axs[2].set_title('Negative')\n",
    "axs[3].set_title('Compound')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPRwrB3LKWs6"
   },
   "source": [
    "The graph indicates that the mean compound score for negative sentiment labels are less than 0.05 while the mean compound score for positive sentiment labels are slightly above 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkXv7G-xKWs6"
   },
   "source": [
    "The graphs above show that the VADER polarity scores are consistent with the labelling of positive and negative movie review sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNGK9lNHKWs6"
   },
   "outputs": [],
   "source": [
    "# Assigning labels based on VADERS results\n",
    "vader_labels = {}\n",
    "for index, row in tqdm(vaders.iterrows(), total=len(vaders)):\n",
    "    if row['compound'] > 0:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "\n",
    "    vader_labels[index] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RaHnojwnKWs6"
   },
   "outputs": [],
   "source": [
    "vaders['vader_labels'] = pd.Series(vader_labels)\n",
    "vaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HfD2kSQtKWs6"
   },
   "outputs": [],
   "source": [
    "# Assign lables\n",
    "y_true = vaders['label']\n",
    "y_pred = vaders['vader_labels']\n",
    "\n",
    "# Classification metrics\n",
    "accuracy = round(accuracy_score(y_true, y_pred), 4)\n",
    "precision = round(precision_score(y_true, y_pred), 4)\n",
    "recall = round(recall_score(y_true, y_pred), 4)\n",
    "f1 = round(f1_score(y_true, y_pred), 4)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred), 4)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHIQV0ssKWs7"
   },
   "source": [
    "As we can see, the VADERS model does not give a satisfactory result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARgMnItRKWs7"
   },
   "source": [
    "# BERT (unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYXpQeWfFhq7",
    "outputId": "f4df952c-c8d8-4da3-ea79-1457845bab81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Training will run on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6E8eoYNsKWs8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1768f5a8be584f758ee5ea634631f707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4d8b21f16b435895695c1ea467b4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8fe0197abd4ee9af4690510f892913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036a09f2f6dd43a0ae0ab76374c8ef02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anaqi_Amir/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7915fa08e5642adbe5a59267d4fce38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a37cf29691d4441bb5f5ca9546addd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_1_star</th>\n",
       "      <th>bert_2_star</th>\n",
       "      <th>bert_3_star</th>\n",
       "      <th>bert_4_star</th>\n",
       "      <th>bert_5_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.392059</td>\n",
       "      <td>0.205056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045276</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>0.186256</td>\n",
       "      <td>0.362144</td>\n",
       "      <td>0.274876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037943</td>\n",
       "      <td>0.157530</td>\n",
       "      <td>0.479475</td>\n",
       "      <td>0.280569</td>\n",
       "      <td>0.044483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.086984</td>\n",
       "      <td>0.418414</td>\n",
       "      <td>0.373449</td>\n",
       "      <td>0.100125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326898</td>\n",
       "      <td>0.445699</td>\n",
       "      <td>0.156506</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>0.022423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>0.493445</td>\n",
       "      <td>0.391335</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>0.011213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>0.291502</td>\n",
       "      <td>0.397941</td>\n",
       "      <td>0.208780</td>\n",
       "      <td>0.074290</td>\n",
       "      <td>0.027486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>0.018334</td>\n",
       "      <td>0.260069</td>\n",
       "      <td>0.635084</td>\n",
       "      <td>0.083141</td>\n",
       "      <td>0.003372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>0.577798</td>\n",
       "      <td>0.358592</td>\n",
       "      <td>0.054986</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.003222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>0.164274</td>\n",
       "      <td>0.524831</td>\n",
       "      <td>0.287307</td>\n",
       "      <td>0.021306</td>\n",
       "      <td>0.002282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bert_1_star  bert_2_star  bert_3_star  bert_4_star  bert_5_star\n",
       "0        0.032359     0.106020     0.264506     0.392059     0.205056\n",
       "1        0.045276     0.131448     0.186256     0.362144     0.274876\n",
       "2        0.037943     0.157530     0.479475     0.280569     0.044483\n",
       "3        0.021029     0.086984     0.418414     0.373449     0.100125\n",
       "4        0.326898     0.445699     0.156506     0.048475     0.022423\n",
       "...           ...          ...          ...          ...          ...\n",
       "8525     0.493445     0.391335     0.083159     0.020848     0.011213\n",
       "8526     0.291502     0.397941     0.208780     0.074290     0.027486\n",
       "8527     0.018334     0.260069     0.635084     0.083141     0.003372\n",
       "8528     0.577798     0.358592     0.054986     0.005403     0.003222\n",
       "8529     0.164274     0.524831     0.287307     0.021306     0.002282\n",
       "\n",
       "[8530 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Tensorflow\n",
    "import torch\n",
    "\n",
    "# Setting up BERT model\n",
    "MODEL = f\"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = model.to(device)\n",
    "\n",
    "# Function to get polarity scores using BERT model\n",
    "def polarity_scores_bert(text):\n",
    "    encoded_text = tokenizer.encode(text, return_tensors='pt')\n",
    "    output = model(encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'bert_1_star' : scores[0],\n",
    "        'bert_2_star' : scores[1],\n",
    "        'bert_3_star' : scores[2],\n",
    "        'bert_4_star' : scores[3],\n",
    "        'bert_5_star' : scores[4]\n",
    "    }\n",
    "    return scores_dict\n",
    "\n",
    "# Running the BERT model on the entire train_df dataset\n",
    "res = {}\n",
    "for index, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    try:\n",
    "        text = row['text']\n",
    "        myid = row['id']\n",
    "        bert_result = polarity_scores_bert(text)\n",
    "        res[myid] = bert_result\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')\n",
    "\n",
    "# Displaying the result in a dataframe format\n",
    "bert = pd.DataFrame(res).T\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LTO5MLo798bj"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21c26bdccc540bdbdbe34b04f8fcde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_1_star</th>\n",
       "      <th>bert_2_star</th>\n",
       "      <th>bert_3_star</th>\n",
       "      <th>bert_4_star</th>\n",
       "      <th>bert_5_star</th>\n",
       "      <th>bert_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032359</td>\n",
       "      <td>0.106020</td>\n",
       "      <td>0.264506</td>\n",
       "      <td>0.392059</td>\n",
       "      <td>0.205056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045276</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>0.186256</td>\n",
       "      <td>0.362144</td>\n",
       "      <td>0.274876</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037943</td>\n",
       "      <td>0.157530</td>\n",
       "      <td>0.479475</td>\n",
       "      <td>0.280569</td>\n",
       "      <td>0.044483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.086984</td>\n",
       "      <td>0.418414</td>\n",
       "      <td>0.373449</td>\n",
       "      <td>0.100125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326898</td>\n",
       "      <td>0.445699</td>\n",
       "      <td>0.156506</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>0.022423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>0.493445</td>\n",
       "      <td>0.391335</td>\n",
       "      <td>0.083159</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>0.011213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>0.291502</td>\n",
       "      <td>0.397941</td>\n",
       "      <td>0.208780</td>\n",
       "      <td>0.074290</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>0.018334</td>\n",
       "      <td>0.260069</td>\n",
       "      <td>0.635084</td>\n",
       "      <td>0.083141</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>0.577798</td>\n",
       "      <td>0.358592</td>\n",
       "      <td>0.054986</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>0.164274</td>\n",
       "      <td>0.524831</td>\n",
       "      <td>0.287307</td>\n",
       "      <td>0.021306</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bert_1_star  bert_2_star  bert_3_star  bert_4_star  bert_5_star  \\\n",
       "0        0.032359     0.106020     0.264506     0.392059     0.205056   \n",
       "1        0.045276     0.131448     0.186256     0.362144     0.274876   \n",
       "2        0.037943     0.157530     0.479475     0.280569     0.044483   \n",
       "3        0.021029     0.086984     0.418414     0.373449     0.100125   \n",
       "4        0.326898     0.445699     0.156506     0.048475     0.022423   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8525     0.493445     0.391335     0.083159     0.020848     0.011213   \n",
       "8526     0.291502     0.397941     0.208780     0.074290     0.027486   \n",
       "8527     0.018334     0.260069     0.635084     0.083141     0.003372   \n",
       "8528     0.577798     0.358592     0.054986     0.005403     0.003222   \n",
       "8529     0.164274     0.524831     0.287307     0.021306     0.002282   \n",
       "\n",
       "      bert_labels  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  \n",
       "...           ...  \n",
       "8525            0  \n",
       "8526            0  \n",
       "8527            0  \n",
       "8528            0  \n",
       "8529            0  \n",
       "\n",
       "[8530 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning labels based on VADERS results\n",
    "bert_labels = {}\n",
    "for index, row in tqdm(bert.iterrows(), total=len(bert)):\n",
    "    neg = row['bert_1_star'] + row['bert_2_star'] + (row['bert_3_star'] / 2)\n",
    "    pos = row['bert_4_star'] + row['bert_5_star'] + (row['bert_3_star'] / 2)\n",
    "    label = 1 if pos >= neg else 0\n",
    "    bert_labels[index] = label\n",
    "\n",
    "# Create prediction column\n",
    "bert['bert_labels'] = pd.Series(bert_labels)\n",
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uxSY-YUm-R3Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7817\n",
      "Precision: 0.7577\n",
      "Recall: 0.8284\n",
      "F1 Score: 0.7914\n",
      "ROC-AUC Score: 0.7817\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      4265\n",
      "           1       0.76      0.83      0.79      4265\n",
      "\n",
      "    accuracy                           0.78      8530\n",
      "   macro avg       0.78      0.78      0.78      8530\n",
      "weighted avg       0.78      0.78      0.78      8530\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign labels\n",
    "y_true = train_df['label']\n",
    "y_pred = bert['bert_labels']\n",
    "\n",
    "# Classification metrics\n",
    "accuracy = round(accuracy_score(y_true, y_pred), 4)\n",
    "precision = round(precision_score(y_true, y_pred), 4)\n",
    "recall = round(recall_score(y_true, y_pred), 4)\n",
    "f1 = round(f1_score(y_true, y_pred), 4)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred), 4)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-k0Jfx-KWs8"
   },
   "source": [
    "## ROBERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oRUKpSJ1KWs8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anaqi_Amir/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up ROBERTA model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FQEE99XWKWs8"
   },
   "outputs": [],
   "source": [
    "# Function to get polarity scores using Roberta model\n",
    "def polarity_scores_roberta(example):\n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gbsOmZCkKWs9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2292dd4a8645faa7851ba77d808674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running the model on the entire train_df dataset\n",
    "res = {}\n",
    "for index, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    try:\n",
    "        text = row['text']\n",
    "        myid = row['id']\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        res[myid] = roberta_result\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hhQZ6xxjKWs9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.078215</td>\n",
       "      <td>0.919535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024806</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.749606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.339475</td>\n",
       "      <td>0.024322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.920688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090276</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.383869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>0.114693</td>\n",
       "      <td>0.432905</td>\n",
       "      <td>0.452402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>0.370913</td>\n",
       "      <td>0.561094</td>\n",
       "      <td>0.067993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>0.264912</td>\n",
       "      <td>0.635328</td>\n",
       "      <td>0.099759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>0.856152</td>\n",
       "      <td>0.125944</td>\n",
       "      <td>0.017904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>0.807661</td>\n",
       "      <td>0.170936</td>\n",
       "      <td>0.021403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      roberta_neg  roberta_neu  roberta_pos\n",
       "0        0.002251     0.078215     0.919535\n",
       "1        0.024806     0.225588     0.749606\n",
       "2        0.636203     0.339475     0.024322\n",
       "3        0.002743     0.076569     0.920688\n",
       "4        0.090276     0.525855     0.383869\n",
       "...           ...          ...          ...\n",
       "8525     0.114693     0.432905     0.452402\n",
       "8526     0.370913     0.561094     0.067993\n",
       "8527     0.264912     0.635328     0.099759\n",
       "8528     0.856152     0.125944     0.017904\n",
       "8529     0.807661     0.170936     0.021403\n",
       "\n",
       "[8530 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the result in a dataframe format\n",
    "roberta = pd.DataFrame(res).T\n",
    "roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MkGuARY1KWs-"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcecbd0648c45c6ad4e45d9d4fec6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8530 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assigning labels based on VADERS results\n",
    "roberta_labels = {}\n",
    "for index, row in tqdm(roberta.iterrows(), total=len(roberta)):\n",
    "    pos = row['roberta_pos'] + (row['roberta_neu'] / 2)\n",
    "    neg = row['roberta_neg'] + (row['roberta_neu'] / 2)\n",
    "    label = 1 if pos >= neg else 0\n",
    "\n",
    "    roberta_labels[index] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Xe4Vj5fRKWtA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_neu</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>roberta_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.078215</td>\n",
       "      <td>0.919535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024806</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.749606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.636203</td>\n",
       "      <td>0.339475</td>\n",
       "      <td>0.024322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>0.920688</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090276</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.383869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8525</th>\n",
       "      <td>0.114693</td>\n",
       "      <td>0.432905</td>\n",
       "      <td>0.452402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>0.370913</td>\n",
       "      <td>0.561094</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>0.264912</td>\n",
       "      <td>0.635328</td>\n",
       "      <td>0.099759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>0.856152</td>\n",
       "      <td>0.125944</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>0.807661</td>\n",
       "      <td>0.170936</td>\n",
       "      <td>0.021403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8530 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      roberta_neg  roberta_neu  roberta_pos  roberta_labels\n",
       "0        0.002251     0.078215     0.919535               1\n",
       "1        0.024806     0.225588     0.749606               1\n",
       "2        0.636203     0.339475     0.024322               0\n",
       "3        0.002743     0.076569     0.920688               1\n",
       "4        0.090276     0.525855     0.383869               1\n",
       "...           ...          ...          ...             ...\n",
       "8525     0.114693     0.432905     0.452402               1\n",
       "8526     0.370913     0.561094     0.067993               0\n",
       "8527     0.264912     0.635328     0.099759               0\n",
       "8528     0.856152     0.125944     0.017904               0\n",
       "8529     0.807661     0.170936     0.021403               0\n",
       "\n",
       "[8530 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta['roberta_labels'] = pd.Series(roberta_labels)\n",
    "roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GQRFEQAzKWtB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7941\n",
      "Precision: 0.8104\n",
      "Recall: 0.7679\n",
      "F1 Score: 0.7886\n",
      "ROC-AUC Score: 0.7941\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      4265\n",
      "           1       0.81      0.77      0.79      4265\n",
      "\n",
      "    accuracy                           0.79      8530\n",
      "   macro avg       0.79      0.79      0.79      8530\n",
      "weighted avg       0.79      0.79      0.79      8530\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhEAAAGdCAYAAACsBCEsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTCUlEQVR4nO3dd3yN5//H8dfJtENEFrH33qv2CIpUB1qaUmrUamoUVbvEaEXNqhotWjqslqa0iipBEav2DhIrQojM8/vDt6e/c2LcOd9owvf97ON+PJz7vu7rXOfU+OTzua77MpnNZjMiIiIiaeSQ0QMQERGRp5OCCBEREbGLgggRERGxi4IIERERsYuCCBEREbGLgggRERGxi4IIERERsYuCCBEREbGLgggRERGxi1NGD+BvWav0y+ghiGQ60btnZfQQRDKlLE/4X6/0/Dcpbt+z++c40wQRIiIimYZJiXoj9C2JiIiIXZSJEBERsWUyZfQIngoKIkRERGypnGGIgggRERFbykQYolBLRERE7KJMhIiIiC2VMwxRECEiImJL5QxDFGqJiIiIXZSJEBERsaVyhiEKIkRERGypnGGIQi0RERGxizIRIiIitlTOMERBhIiIiC2VMwxRqCUiIiJ2USZCRETElsoZhiiIEBERsaVyhiEKIkRERGwpE2GIviURERGxizIRIiIitpSJMERBhIiIiC0HzYkwQqGWiIiI2EWZCBEREVsqZxiiIEJERMSWlngaolBLRERE7KJMhIiIiC2VMwxRECEiImJL5QxDFGqJiIiIXZSJEBERsaVyhiEKIkRERGypnGGIgggRERFbykQYom9JRERE7KJMhIiIiC2VMwxRECEiImJL5QxD9C2JiIiIXZSJEBERsaVyhiEKIkRERGypnGGIviURERGxizIRIiIitpSJMERBhIiIiC3NiTBEoZaIiIjYRZkIERERWypnGKIgQkRExJbKGYYoiBAREbGlTIQh+pZERETELspEiIiI2FI5wxAFESIiIjZMCiIMUTlDRERE7KJMhIiIiA1lIoxRECEiImJLMYQhKmeIiIiIXZSJEBERsaFyhjEKIkRERGwoiDBG5QwRERGxizIRIiIiNpSJMEZBhIiIiA0FEcYoiBAREbGlGMIQzYkQERERuygTISIiYkPlDGMURIiIiNhQEGGMyhkiIiJiF2UiREREbCgTYYwyESIiIjZMJlO6HWkxd+5cKlasSK5cuciVKxd16tThp59+slw3m82MGTMGX19fsmbNSqNGjTh8+LBVH/Hx8fTv3x8PDw+yZ89OQEAAERERVm2io6MJDAzEzc0NNzc3AgMDuXnzZpq/JwURIiIimUSBAgWYNGkSf/75J3/++SdNmjThhRdesAQKU6ZMYdq0acyaNYvdu3fj7e1N8+bNuX37tqWPoKAgVq1axfLly9m2bRuxsbG0adOG5ORkS5tOnToRHh5OaGgooaGhhIeHExgYmObxmsxms/m//9j/vaxV+mX0EEQynejdszJ6CCKZUpYnXIzP2+XrdOvr+hev/Vf3u7u7M3XqVLp164avry9BQUEMHToUuJ918PLyYvLkyfTq1YuYmBjy5cvHkiVL6NixIwCXLl3Cz8+P9evX06JFC44cOULZsmUJCwujVq1aAISFhVGnTh2OHj1KqVKlDI9NmQgREREb6VnOiI+P59atW1ZHfHz8Y8eQnJzM8uXLuXPnDnXq1OHMmTNERkbi7+9vaePq6krDhg3Zvn07AHv27CExMdGqja+vL+XLl7e02bFjB25ubpYAAqB27dq4ublZ2hilIEJEROQJCg4Otsw9+PsIDg5+aPuDBw+SI0cOXF1d6d27N6tWraJs2bJERkYC4OXlZdXey8vLci0yMhIXFxfy5MnzyDaenp6p3tfT09PSxiitzhAREbGRnqszhg8fzsCBA63Oubq6PrR9qVKlCA8P5+bNm3z//fd06dKFLVu2PHRsZrP5seO1bfOg9kb6saVMhIj8z1izaiX1alfP6GHIUyA9yxmurq6W1RZ/H48KIlxcXChevDjVq1cnODiYSpUq8cknn+Dt7Q2QKltw5coVS3bC29ubhIQEoqOjH9kmKioq1ftevXo1VZbjcRREZFJx+2Y98vhs7Ov/2lg+G/s6cftmMfjN5lbn2zaqSNw+TfyTf9fI94dRqVypVMf5c+cyemisWbXSakxNG9ZjyMB3iIi4kNFDk7QypePxXzKbzcTHx1OkSBG8vb3ZuHGj5VpCQgJbtmyhbt26AFSrVg1nZ2erNpcvX+bQoUOWNnXq1CEmJoZdu3ZZ2uzcuZOYmBhLG6NUzsikCjcbbvn1K/7VGPl2ayq9OM5yLi4+0aq9k5MDSUkpT2w8cfcSGNi1OZ9/t42bt+Oe2PuIGPFcvfqM+9C6ppzH3T2DRmMtR44crPkxFDNmzpw+zfixo3mnXx+++X41jo6OGT08yeTef/99WrVqhZ+fH7dv32b58uVs3ryZ0NBQTCYTQUFBTJw4kRIlSlCiRAkmTpxItmzZ6NSpEwBubm50796dQYMGkTdvXtzd3Rk8eDAVKlSgWbNmAJQpU4aWLVvSo0cP5s2bB0DPnj1p06ZNmlZmgDIRmVbU9duWIyY2DjNmy2tXF2eifv+Il5tX4ef57xAdFsJrz9dkRK/nCVs+zKqffp0acXTdWKtzgQG12ff9B0SHhRC+8gN6tq//2PFs2nmMqGu3GNLN/5HtalcqwsYFQdzYMY0TP43n4/deIVsWF8t1b49crJzRmxs7pnHkxzF0bFmdo+vG0q9TI+NfjvzPc3FxwSNfPqvD0dGRLxcv4uV2balVvTL+TRsyYdwY7t6589B+jh09SveugdSpUYW6NavyavuXOHzooOV6+L69vPlGZ2pWrYh/04ZMmvghd+/efeTYTCYTHvnykS+fJzVr1aZ3n76cPHGcC+fvZ0q+Wf4VrVs2o1ql8gS0bsEPa1db3T939kxaNG1E9crladaoHpMmfmj39yT2y6iHTUVFRREYGEipUqVo2rQpO3fuJDQ0lObN72eC33vvPYKCgujTpw/Vq1fn4sWLbNiwgZw5c1r6CAkJoV27dnTo0IHnnnuObNmy8cMPP1gFscuWLaNChQr4+/vj7+9PxYoVWbJkSZq/J2UinmIfvvMCw6atoufoCBISk+j20nOPvefNF+sy8u3WvDvpG8KPRlC5dAFmj+zEnXsJLPth50PvS0lJYfSstSye2JU5X2/h4pWbqdqUK+7L2tl9GTfnR3qPXUa+PDmYNrQDIcM60GvMUgA+H/8GeXNnp0WPT0hMSmbyoJfJlydnqr5E7OHgYGLo8BH45s/PxYgIJn44lpCPpzJi1JgHth8+dDCly5Thg1FjcHB05NjRIzg5OQNw4vgx3u7Znb7932HM+AlE37hB8ITxBE8Yz/gJD59Zb8vVNQsAiUlJ/PrLRiYHT+S9YcOpVacuWzdvZvQH7+Pl5U3NWrXZ+HMoS79czOSPplGsWAmuXbvG8WNH/+vvRdIuox57vWDBgkdeN5lMjBkzhjFjxjy0TZYsWZg5cyYzZ858aBt3d3eWLl1q7zAtlIl4is1atpk1m/Zz7tJ1Ll+NMXTP8B4tGTZtpeW+NZv2M3PZJt56+fEByNrfDnDg+EU+ePv5B15/t0tTVvz0J7O+2syp81cJ23+GwVO+pXObmri6OFGysBdNa5em7/iv2X3oHOFHI3h73DKyZXV5YH8iD7N1y2ZqV69iOQa/OwCA19/oSs1atSlQwI9atevQt/87bPj5p4f2E3n5ErVr16VI0WIUKlQY/xatKFW6NACLFy2gVeu2vP5GVwoVKkzlKlUZOnwEP65dbWiNP0BUZCRfLFqAl7c3hQsV5stFC3ih3Yt0fK0zhQsX4Y2ub9K0WXO+XLwQuF+7zuvhQa3adfHx9aVCxYq83L7Df/ltiTw5ykQ8xfb+dT5N7T3y5MDPx525ozoze2Qny3knRwdiYo3NcxjxyWpC5w3gkyWbUl2rUqYgxfw8ePX5GpZzJhM4OjpQOH9eShTyJDExmX1H/plkdvrCNW7EPDzdLPIgNWrWYsTIMZbXWbNlBWDXzjAWzJ/HqVMnuRMbS3JyMvHx8dy9e5ds2bKl6iewy5uMHf0BP/6whlq16+LfoiV+BQsC8Nfhw1w4f471P/5gaW/GTEpKChcjIiharNgDx3b79m1qV6+CGTP34uIoU7Yc06bPxNnFhdOnT/Ny+45W7StXqcqypV8C4N+iJcuWfEHrls147rn61GvQkIaNGuPkpL+q/23agMsY/c58it2Js/5pKMWcgu3ve2enf2pgDv+52Hf8V+w6dNaqXXKysaef/7H3FBt3HGFcv7YsWWtd/nAwmVjw/R/M/npzqvsuXI6mZKEHLx3SH1ZJq6xZs1KwUCGrc5cuXaTf2z1p3+FV+vZ/h1xubuzbu4cxI0eQlJT0wH7e7tufVq3b8PuWLWzbtpW5s2cw+aMQmjZrjtmcwisdXqVT59T7Cfj4+Dx0bNmzZ2f5t6twcHDAPW/eVMHLo9b4e/v4sGZdKGHb/yAsbAcTx4/li0ULWLB4Cc7Ozoa+G0kf+nvJGAURz5Br0bF45c1lda5iqQKWX1+5cZuLUdEULuDB8p/+tPt9Rs5Yy87lwzhx7orV+fCjFyhT1IfTF6498L5jZ6NwdnakcukClmxEUT8P8uRK/ROiSFr9degQycnJDHpvGA4O9yu1G0IfXsr4W+HCRShcuAiBXboydPBA1qz6nqbNmlOmTFlOnTyRKlh5HAcHh4feU7RoUfbt3UPbF9pZzu0P30eRov9kNbJkyUKjJk1p1KQpr77WiRfatOLkieOUKVsuTeMQ+TdoTsQzZOufJ8iXJweDujajSAEPenVogP9zZa3afDhvPUPe9Kfva40oXtCTcsV9CQyozYDXmxh+n8MnL7H8p928/WpDq/MfL95IrYpFCBnWgYol81OsYD5aN6zAtKHtATh+Nopfw44y64PXqF6uEJVKFWD2B69xNy6BzLENnDzNCvgVJCkpia+XLSHiwgV+WLuab79Z/tD29+7dY+KH49i9ayeXLl1k3949HD500PIP+pvde3BgfzgTx4/l6JEjnDt3ls2bfiV4wni7x9il21usWb2Kb1Z8zblzZ/ly8SJ+/WUjXbp2A+4/Z2Ll999y4sRxIi5c4Me1a8iSJQs+vr52v6fYKRM9JyIzUybiGXLsTBTvBH/De938GdajFat/DWf6l7/S/f9Nmly8agdxcYkEdWnKhKAXuBOXwOGTl5i17Lc0vde4OT/ycvOqVucOnbiE/1vTGdOvLb8sfBeTycTpiKt89/NeS5u3Rn7J3NGd2bggiKjrtxg1cy1livlwLyHR9i1E0qR0mTIMfm84ixbMZ8b0aVStVp0BQQP5YPjQB7Z3dHAg5uZNPhg+lOvXr5E7Tx6aNvOnT7/7kzRLlirNgsVLmDljOm++0QmzGfz8/GjR6sETi41o0rQZQ4e/zxeLFjB54gTyF8jP2A8nUqPm/Y2QcubKxcLPP+PjKZNITk6hRMmSzJj9Kblz53lMz5LeVM4wRluBS4bK75mbkz9/SKteM9i863hGDyfT0VbgIg/2pLcCz//2qnTr6+LcF9Otr8xGmQj5VzWsUZIc2Vw5dOISPvlyMeGddpy9eI1te09m9NBERCyUiTBGQYT8q5ydHBnbry1F8ntw++49du4/w5sjFj/RR3aLiKSVgghjFETIv+qXHUeo3v5IRg9DROTRFEMYotUZIiIiYhdlIkRERGyonGGMgohnTI/29ejxSn0K+d7fFvnI6UgmfvYTG/74K1XbmSNe5a1X6jFk6nfM+mqz5XyRAh5MevdF6lQpiquzExu3H2Hg5G+5cuO2pU3l0gX48J12VCtXkORkM6t/DWfox99zJy7hiX9GkfTQqnkTLl26mOp8x1c78f7I0QCcPnWK6dOmsufP3aSkpFCseAmmfjzd6rkN+8P3MfOTEA4ePICzkxOlSpdh9qfzyZIly7/2WST9KYgwRkHEM+Zi1E1GzlzDqfP3nxr5ettafBvSk9qvTuLI6UhLu7aNKlKjQmEu2ezGmS2LCz/O6cvB4xdp1fP+DnCj+7Tm+0960eCNjzGbzfjkc2Pdp/35bsNe3p30DbmyZ2HqkJeZPy6QTkMevQOdSGaxbMV3pCQnW16fPHmCXm+9SfMWLQG4cP48XQM78eJLL/N2vwHkzJGT06dP4eLqarlnf/g++vR6i25v9WLYiJE4Oztz/OhRyxMzRZ51CiKeMeu3HrJ6PWb2D/RoX4+aFYtYggjffG6EDGtP2z6zWTXzbav2dSoXpZBvXmq/Npnbd+4B0HP0Ui5vnUqjmiX5becxWtUvT2JSMkHB3/D3Y0aCgr9h54rhFPXzeOhjr0UyE3d3d6vXCz//DD+/glSvUROAmTNCqNegAe8Ofs/SpoCfn9U9UycH81rnQLr36Gk5V6hQ4Sc3aPnXKBNhjMLlZ5iDg4n2LaqRPasLOw+cAe7/wVjw4RuEfPGrVWbib64uTpjNZuIT/tmw6F5CEsnJKdStXMzSJjExmf//nLK4+PtPnPy7jcjTJDEhgXU/rqXdSy9jMplISUnh9y2bKVSoML17dKdR/Tp0frU9m379xXLP9evXOXhgP+558/JG51dp3KAu3bq8zt499u9LI5mHyWRKt+NZluYgIiIighEjRtC4cWPKlClD2bJlady4MSNGjODChQuP70CeuHLFfbn6x8fE7JzOjBEd6ThoPkf/EzAMerM5SckpD9xpE2DXwbPciUtgwjsvkDWLM9myuBAc1A5HRwe8Pe5v7rV51zG88ubi3Tea4uzkSO6cWRnXPwAA73xu/8pnFElPmzb9wu3btwlod//JgjeuX+fu3bssXDCf5+rV59PPFtKkaXMGvtOPP3fvAuBixP2/7z6dPYuXXmnPnHmfU6ZMWXp278q5c2cz6qOI/KvSVM7Ytm0brVq1ws/PD39/f/z9/TGbzVy5coXVq1czc+ZMfvrpJ5577rlH9hMfH098vPU21uaUZEwOjg+5Q9Li+Nkoar0aTO6c2WjXtDLzxwXi/9YnZHV1pu9rjajbafJD770WHUvn9xYw4/2O9HmtISkpZr4J3cPev86TnHL/gVBHTkfSY9QSJg16iXH9A0hOSWHO11uIvHaLlGQ9NEqePqu+/57n6jXA0/P+dvUp5vu/jxs3bkpgl67A/b059ofv5dsVy6leoyYp//nz8EqHjrR78WUAypQpy86dO1i98nveeXfQv/9BJP082wmEdJOmIOLdd9/lrbfeIiQk5KHXg4KC2L179yP7CQ4OZuzYsVbnHL1q4OxTMy3DkYdITEq2zEvY+9d5qpUrSN/XGnHsTCSe7jk4vn6cpa2TkyOTBr5Ev86NKd36/oz0X8OOUi5gLHlzZycpKYWY2DjObJzIuYvXLfetCP2TFaF/4umekztx8ZjNMOD1Jpz9f21EngaXLl1kZ9h2pn0y03IuT+48ODk5UbSYdXmuSNFihO/dA4BHvnwAD2wTefnSEx61PGnPehkivaQpiDh06BBLly596PVevXrx6aefPraf4cOHM3DgQKtznvUfvNOe/PdMmHB1ceKrdbvZtPOY1bUf5vTlq3W7+HJNWKr7rt+8A9zf78LTPQc/bjmYqs3fyz7feKE29xIS+TXs6BP4BCJPzppVK3F3z0v9Bo0s55xdXChXvgJnz56xanvu3Fl8fPMDkD9/AfJ5enL2jE2bs2epV7/BEx+3SGaQpiDCx8eH7du3U6pUqQde37FjBz4+Po/tx9XVFdf/t0wKUCkjnYzt15YNf/zFhchocmbPQvsW1WhQvQQBfedwI+YON2LuWLVPTEom6totTpy7YjkXGFCbY2ciuRodS62KRfhoyCvMXPabVZveHRsQtv80sXcTaFq7NBOD2jFy5hpiYuP+tc8q8t9KSUlhzaqVtH2hHU5O1n8ddnmzO+8Nepdq1WpQo2Yt/tj2O1s3/8bni74E7v+k2vXN7sydPZNSpUpTqnQZ1q5Zxdkzp/k4ZEZGfBxJR8pEGJOmIGLw4MH07t2bPXv20Lx5c7y8vDCZTERGRrJx40Y+//xzpk+f/oSGKkZ45s3Jgg/fwNsjFzGx9zh04iIBfeewaafxDEHJwp6M6x+Au1s2zl26wZQFPzNj6SarNtXLF+KD3q3Jkc2FY2ej6Dfha75e9+gylkhmE7ZjO5cvX6LdSy+nuta0WXM+GD2GhfM/Y3LwhxQuXISPp8+garXqljavv9GV+PgEpk4JJiYmhlKlSvPp/IX4FSz4b34MeQIUQxhjMv//dXoGrFixgpCQEPbs2UPyfx7U4ujoSLVq1Rg4cCAdOnSwayBZq/Sz6z6RZ1n07lkZPQSRTCnLE37KUYkhoenW14mpLdOtr8wmzf8bOnbsSMeOHUlMTOTatfuT9zw8PHB2dk73wYmIiEjmZXcs5+zsbGj+g4iIyNNG5Qxj9NhrERERG5pYaYweey0iIiJ2USZCRETEhhIRxiiIEBERseHgoCjCCJUznmKDu/kTt28WUwf/s8b9hSaVWDu7Lxc2TSJu3ywqlsxvqK92TSuz9/sR3NwZwt7vRxDQuGKq99q2dAhXtn3EuV+D+WZaD0oU8rRqExTYlLO/TOTsLxPp37mx1bUa5Qvxx7L39AdT/hVJSUnM+iSEVv5NqFm1Is+3aMqnc2ZZ9rt4mOVfLaNd21bUrFqRgNYt+GHN6lRtln65mIDWLahZtSL+TRsyddJEq72A1v24Fv+mDalfpybTPrLep+bixQjaPt+C2NjYdPmcIhlNmYinVLWyBen+Ul0OHI+wOp8tqws79p9i5S97mTuqs6G+alUswpJJbzJ27jrWbtpPQJNKLJ3cnabdprH70DkA6lctzqcrtrLn8DmcnBwZ07ctP87tR5WXPuTuvQTKFfdl5NuteemdTzGZYOUnvfk17Ch/nbqMk5MDM0a8Sr/xX5OSkqbHkojYZdGC+Xz7zXLGT5xMseLF+evQIUZ9MJycOXPSObDLA+/5ZvlXzJj+MaPGfkj58hU4ePAA40Z/QM5cuWjUuAlwP0D4JORjxo6fSKUqVTh39iyjRgwDYMiw94mOvsHYUR8wbsIkChQoQL8+vaheoxYNGjYCYMK4Mbzz7iBy5Mjxb3wN8l9QOcMYBRFPoexZXVg0sSt9xn/NsLesH2Ly91MjC/q4G+6vX6dG/LrzKB8t3ADARws3UL9qcfp1bkyX4YsBeKHfHKt7eo1ZyoVNk6hS1o8/9p6idBEvDp24yJbdxwE4dOISpYt489epy7z7RjP+2HuSPX+dt/cji6TJ/v3hNGrS1PKPd/78Bfhp/ToOHz700Ht+/GEtr3ToSMtWzwNQwM+Pg/vDWbRgviWI2B8eTuUqVXm+TVtLvy2fb8OhgwcAiLgQQY4cOS191KhZi9OnTtKgYSPW//gDzs7ONGvu/6Q+tqQjrc4wRuWMp9D04R0J/f0Qv9lspmWvWhWL8OsO68di/7LjCLUrFX3oPblyZAEgOuYuAIdOXqJ4IU/8vPNQ0CcPxQt5cvjUJYr6eRAYUJsxs39Ml7GKGFGlSjV2hYVZNtA6dvQo+/btoX79hg+9JyEhARcX6z19XLNk4dDBgyQmJt7vt2o1jvx1mIMH/g4aLrDt9y2WzbsKFSrEvXtxHDnyFzE3b3L40EFKlCxFzM2bzJk1g+EjRj2BTyuScZSJeMq0b1GNyqX9qPf6lHTr08sjF1eu37Y6d+X6bbzy5nzoPZMHvcwfe0/y16nLABw7E8XoWT/w49z7jy8fNXMtx85Ese7TfoyYvprmdcswotfzJCYlM3jqd/yx91S6jV/EVre3ehAbe5t2bVrh6OhIcnIy/d95l1at2zz0nrrP1WPV99/RpGkzypQtx1+HD7F61fckJSVy82Y0+fJ50ur51kRH36BrYCfATFJSEh06vkb3Hj0ByOXmxviJk/lg+FDi792jbUA7nqtXn1EfDOe1zq9z8WIEA/q9TVJSEm/36UfzFs/u45CfdkpEGKMg4ilSwCs3U4e8TNs+s4lPSErXvs1Yz1UwmeBhu6qEDOtAhRK+NH0zxOr8599t4/Pvtllev962FrF34tl54Az7V4+k3utTye+ZmyWTulG69WgSEtP3M4j8LfSn9az7cS3BUz6mePHiHD16hKmTgsmXz5OAdi8+8J6evftw7dpVAjt1xGw24543LwEvvMjihZ/j8J9dhnfv2snn8z5lxMjRVKhYkfPnzzMleAIec2fT6+2+wP2Nu5o2a27pd/eunZw8fpzhI0bRtlVzJk2dhoeHB51fbU/V6jXImzfvk/9CJM1UzjBGQcRTpEqZgnjlzcX2Ze9Zzjk5OVKvajF6d2yAW60guyYuRl27hVfeXFbn8rnn5MqN26naThvanjYNK9Cs+3QuXrn50D7z5s7O+z1b0bz7dGpUKMzJc1c4df4qp85fxcnJgRKFPDl88lKaxypiRMjHU+jWvSetnm8NQImSpbh86RILPp/30CAiS5YsjPswmJGjx3Hj+nU88uXj+29XkD17dvLkyQPA7Jmf0CYggJdeaW/pNy7uLuPHjKJHr7dxcLCuECckJDBx/FgmTp7KhfPnSEpOpnqNmgAUKlSYgwf2W+ZbSOaiIMIYBRFPkd92HaPaKxOszn029nWOnYni48Ub7V75sPPAGZrULs3MZb9ZzjWtU5qw/aet2oUMbU9Ak0r49/iEc5euP7LPqYNfZuay37h45SbVyhXEycnRcs3J0RFHLfWUJ+he3L1Uy4kdHR0N/RlxdnbGy9sbuJ/RaNCwsSU4uHfvHiaTdaDg6OCI2WzmQRsifzZ3Ns/Vb0CZsuU4cuQvkpOSLdeSkpIeu+RUJLNTEPEUib0bb5mD8Lc7cQnciLljOZ8nVzb8vPPg4+kGQMnCXgBEXb9F1H/mPXw+PpBLV2IYNXMtALO/3szGz4MY1LUZP2w+SNtGFWhSszRNu02zvM/04R3o2Ko67d/9jNg79yzzJWJi73EvPtFqTE1qlaZ4QU+6j1wCwJ+HzlGqsBf+z5WlgFcekpNTOH7uSnp/PSIWDRs1Zv5nn+Lt40ux4sU5euQIS75YxAsv/vNMlU9CPubKlSgmBN+fX3T27BkOHTxAhYqVuBVziyVfLuLkiROMnzjJqt8lXyyidJmyVKhYkQvnzzN75ic0bNwER0dHqzGcPHmCn0N/YsX3qwEoUqQoDg4mVn7/LR4e+Thz5jTlyld48l+G2EWJCGMURDxjWjeswPxxgZbXSyZ3A+DDT9czYd56APy83a1+Igvbf4Y3hi9idJ82jOrThtMXrhE4bKHlGREAvTo0AGDj50FW79dj1BKW/rDT8jqLqzMhw9oTOHSh5SezS1djGDjlW+aNeZ2ExCR6jFqSKvAQSU/DRnzA7BmfMHH8WG7cuE4+T09ead/RMm8B4NrVq0Re/icoT0lO4cvFizh39gxOTk7UqFmLL5d9Tf78BSxtevR6G5PJxOwZ07lyJYo8edxp2Kgx/d551+r9zWYz40ePZPDQ4WTLlg34T7lkwiSCPxxHQkICw0eMwsvL6wl/E2IvlTOMMZkflIPLAFmr9MvoIYhkOtG7Z2X0EEQypSxP+EfgKmM3pVtf+0Y/u/NelIkQERGxoUSEMQoiREREbKicYYyeWCkiIiJ2USZCRETEhhIRxiiIEBERsaFyhjEqZ4iIiIhdlIkQERGxoUSEMQoiREREbKicYYyCCBERERuKIYzRnAgRERGxizIRIiIiNlTOMEZBhIiIiA3FEMaonCEiIiJ2USZCRETEhsoZxiiIEBERsaEYwhiVM0RERMQuykSIiIjYUDnDGGUiREREbJhMpnQ70iI4OJgaNWqQM2dOPD09adeuHceOHbNq07Vr11TvUbt2bas28fHx9O/fHw8PD7Jnz05AQAARERFWbaKjowkMDMTNzQ03NzcCAwO5efNmmsarIEJERCST2LJlC3379iUsLIyNGzeSlJSEv78/d+7csWrXsmVLLl++bDnWr19vdT0oKIhVq1axfPlytm3bRmxsLG3atCE5OdnSplOnToSHhxMaGkpoaCjh4eEEBgamabwqZ4iIiNjIqGpGaGio1etFixbh6enJnj17aNCggeW8q6sr3t7eD+wjJiaGBQsWsGTJEpo1awbA0qVL8fPz45dffqFFixYcOXKE0NBQwsLCqFWrFgDz58+nTp06HDt2jFKlShkarzIRIiIiNtKznBEfH8+tW7esjvj4eEPjiImJAcDd3d3q/ObNm/H09KRkyZL06NGDK1euWK7t2bOHxMRE/P39Led8fX0pX74827dvB2DHjh24ublZAgiA2rVr4+bmZmljhIIIERERGyZT+h3BwcGWeQd/H8HBwY8dg9lsZuDAgdSrV4/y5ctbzrdq1Yply5axadMmPv74Y3bv3k2TJk0sgUlkZCQuLi7kyZPHqj8vLy8iIyMtbTw9PVO9p6enp6WNESpniIiIPEHDhw9n4MCBVudcXV0fe1+/fv04cOAA27ZtszrfsWNHy6/Lly9P9erVKVSoEOvWreOll156aH9ms9lqoueDJn3atnkcBREiIiI20nOJp6urq6Gg4f/r378/a9euZevWrRQoUOCRbX18fChUqBAnTpwAwNvbm4SEBKKjo62yEVeuXKFu3bqWNlFRUan6unr1Kl5eXobHqXKGiIiIjfQsZ6SF2WymX79+rFy5kk2bNlGkSJHH3nP9+nUuXLiAj48PANWqVcPZ2ZmNGzda2ly+fJlDhw5Zgog6deoQExPDrl27LG127txJTEyMpY0RykSIiIhkEn379uWrr75izZo15MyZ0zI/wc3NjaxZsxIbG8uYMWN4+eWX8fHx4ezZs7z//vt4eHjw4osvWtp2796dQYMGkTdvXtzd3Rk8eDAVKlSwrNYoU6YMLVu2pEePHsybNw+Anj170qZNG8MrM0BBhIiISCoOGbTGc+7cuQA0atTI6vyiRYvo2rUrjo6OHDx4kC+//JKbN2/i4+ND48aNWbFiBTlz5rS0DwkJwcnJiQ4dOhAXF0fTpk1ZvHgxjo6OljbLli1jwIABllUcAQEBzJo1K03jNZnNZrOdnzVdZa3SL6OHIJLpRO9O2x9okf8VWZ7wj8D+s8PSra8NfWs/vtFTSnMiRERExC4qZ4iIiNjQBlzGKIgQERGx4aAYwhAFESIiIjaUiTBGcyJERETELspEiIiI2FAiwhgFESIiIjZMKIowQuUMERERsYsyESIiIja0OsMYBREiIiI2tDrDGJUzRERExC7KRIiIiNhQIsIYBREiIiI2MmoXz6eNyhkiIiJiF2UiREREbCgRYYyCCBERERtanWGMgggREREbiiGM0ZwIERERsYsyESIiIja0OsMYBREiIiI2FEIYo3KGiIiI2EWZCBERERtanWGMgggREREb2sXTGJUzRERExC7KRIiIiNhQOcMYBREiIiI2FEMYo3KGiIiI2EWZCBERERsqZxijIEJERMSGVmcYoyBCRETEhjIRxmhOhIiIiNhFmQgREREbykMYoyBCRETEhnbxNEblDBEREbGLMhEiIiI2lIgwRkGEiIiIDa3OMEblDBEREbGLMhEiIiI2lIgwRkGEiIiIDa3OMEblDBEREbGLMhEiIiI2lIgwRkGEiIiIDa3OMCbTBBFntoRk9BBEMp08z0/N6CGIZEpxG4Y80f5V6zdG35OIiIjYJdNkIkRERDILlTOMURAhIiJiw0ExhCEqZ4iIiIhdlIkQERGxoUyEMQoiREREbGhOhDEqZ4iIiIhdlIkQERGxoXKGMQoiREREbKiaYYzKGSIiImIXZSJERERsaCtwYxREiIiI2FCa3hgFESIiIjaUiDBGwZaIiEgmERwcTI0aNciZMyeenp60a9eOY8eOWbUxm82MGTMGX19fsmbNSqNGjTh8+LBVm/j4ePr374+HhwfZs2cnICCAiIgIqzbR0dEEBgbi5uaGm5sbgYGB3Lx5M03jVRAhIiJiw8FkSrcjLbZs2ULfvn0JCwtj48aNJCUl4e/vz507dyxtpkyZwrRp05g1axa7d+/G29ub5s2bc/v2bUuboKAgVq1axfLly9m2bRuxsbG0adOG5ORkS5tOnToRHh5OaGgooaGhhIeHExgYmKbxmsxmszlNdzwhkbcSM3oIIplOkVemZ/QQRDKluA1Dnmj/o34+kW59jWtRwu57r169iqenJ1u2bKFBgwaYzWZ8fX0JCgpi6NChwP2sg5eXF5MnT6ZXr17ExMSQL18+lixZQseOHQG4dOkSfn5+rF+/nhYtWnDkyBHKli1LWFgYtWrVAiAsLIw6depw9OhRSpUqZWh8ykSIiIg8QfHx8dy6dcvqiI+PN3RvTEwMAO7u7gCcOXOGyMhI/P39LW1cXV1p2LAh27dvB2DPnj0kJiZatfH19aV8+fKWNjt27MDNzc0SQADUrl0bNzc3SxsjFESIiIjYcDCl3xEcHGyZd/D3ERwc/NgxmM1mBg4cSL169ShfvjwAkZGRAHh5eVm19fLyslyLjIzExcWFPHnyPLKNp6dnqvf09PS0tDFCqzNERERspOdzIoYOH87AgQOtzrm6uj72vn79+nHgwAG2bduW6prtBmFms/mxm4bZtnlQeyP9/H/KRIiIiDxBrq6u5MqVy+p4XBDRv39/1q5dy2+//UaBAgUs5729vQFSZQuuXLliyU54e3uTkJBAdHT0I9tERUWlet+rV6+mynI8ioIIERERGyZT+h1pYTab6devHytXrmTTpk0UKVLE6nqRIkXw9vZm48aNlnMJCQls2bKFunXrAlCtWjWcnZ2t2ly+fJlDhw5Z2tSpU4eYmBh27dplabNz505iYmIsbYxQOUNERMRGRu3i2bdvX7766ivWrFlDzpw5LRkHNzc3smbNislkIigoiIkTJ1KiRAlKlCjBxIkTyZYtG506dbK07d69O4MGDSJv3ry4u7szePBgKlSoQLNmzQAoU6YMLVu2pEePHsybNw+Anj170qZNG8MrM0BBhIiISKYxd+5cABo1amR1ftGiRXTt2hWA9957j7i4OPr06UN0dDS1atViw4YN5MyZ09I+JCQEJycnOnToQFxcHE2bNmXx4sU4Ojpa2ixbtowBAwZYVnEEBAQwa9asNI1Xz4kQycT0nAiRB3vSz4mY+OupdOvr/abF0q2vzEaZCBERERsZVc542iiIEBERsaEgwhitzhARERG7KBMhIiJiIy0PXPpfpiBCRETEhsoZxqicISIiInZRJkJERMSGqhnGKIgQERGxkZ4bcD3LVM4QERERuygTISIiYkMTK41RECEiImJD1QxjVM4QERERuygTISIiYsMBpSKMUBAhIiJiQ+UMYxREiIiI2NDESmM0J0JERETsokyEiIiIDT1syhgFESIiIjYUQxijcoaIiIjYRZkIERERGypnGKMgQkRExIZiCGNUzhARERG7KBMhIiJiQz9hG6MgQkRExIZJ9QxDFGyJiIiIXZSJEBERsaE8hDEKIkRERGxoiacxCiJERERsKIQwRnMiRERExC7KRIiIiNhQNcMYBREiIiI2tMTTGJUzRERExC7KRIiIiNjQT9jGKIgQERGxoXKGMQq2RERExC7KRIiIiNhQHsIYBREiIiI2VM4wRuUMERERsYsyESIiIjb0E7YxCiJERERsqJxhjIIIERERGwohjFHGRkREROyiTISIiIgNVTOMURAhIiJiw0EFDUNUzhARERG7KIh4hvz0w2paN66T0cMQEXnqmUzpdzzLVM7IZILHjCB03ZpU55etXE8Bv4IZMKJ//PTDaiaN+4CatZ9j6sx5lvO3b9+iTZO6TP90IVWq1czAEcr/krgNQx55fcmGQ/T86Kd/ZSyfDW5FoH95ABKTkom4eps1204wfskf3L2X+K+MQdKXSeUMQxREZEI169Rj2KgPrc7lzpMng0ZjzdHRiT27d7L3z11Ura6AQTJO4Y5zLL9+pWEpRnapR6VuCyzn4uKt//F2cnQgKTnliY3n592n6fVRKM5ODjxXvgBz3m1BtizOvDNz4xN7T5GMpiAiE3JxcSGvh0eq8yuWfcFPP6zm8sUIcubKRd36jeg9YBDZsmV7YD8njx9l5rTJHDtyGJPJRAG/QgwaPorSZe//xHRo/z7mzZ7O0b8O4eaWm/qNm9KzbxBZsz64P4CsWbPSqFkLPpsVwqeLv35ou6tXopgdMoXdO3fg4GCiQqWq9B80DB/f/AAkJSUxe/oUNqz7AQdHB1q/8DI3rl/jTmwsEz6akZavS/5HRUXfsfw65k48ZrPZcq6gVy7OrujD6x+upWfbytQs48uAGRsp6JWLtnVLUPvtLyz39nuxGv1erEbpNz6znAv0L8/ADjUp7O3GuagY5qzey2c/hD9yPAmJyZb3X/HbERpU8qNt3eK8M3MjLs6OBPdoyCuNSpMrmyt7j0fy3qe/sed4JAC5c7gS0q8ZTasWJkdWZy5ei2XK12Es2XAovb4uSaNnvQyRXjQn4iniYHJgwODhLF6+ivfHTGTfn7v4dMbHD23/4chh5PP0Yt4Xy5n/5Td06tIdJ6f7ceOpk8cZPKAXDRo1Y9FXKxkz8SMOhu9j+pSJjx3Hmz37cPrkCTb/uuGB1+/diyPo7W5kzZaNGZ8tZub8L8maNRvvDehNYuL9nw6//nIBv4SuY+io8cz6fAl37sSybfMmO74VkYf78K0GzFm9l8pvLeSXP88YuufNVhUZ+2Z9xiz6ncpvLWT0wt8Z1aUenZuXS9N730tIwtnp/l+xE99qSLt6Jekx9Sfq9PmSU5dusnbiK+TJmQWA0V3qUbpgXtqN+I7Kby1kwIyNXL8Vl7YPK+nKAVO6Hc8yBRGZ0I5tW2jZoIblGDVsIADtOwVStXpNfPIXoGqNWnTr3Y/Nv/z80H6ioi5TvWYdChUuSoGChWjcrAXFS5YGYPmSRTRr0Zr2nQIpULAQ5StVYcDg4WxYv5b4+PhHjs8jnyevvNqZz+fMICkpKdX1Xzf8hIPJgfc+GEex4iUpXKQYw0Z/SFTkZcL37AJg5Yqv6NzlLRo0bkahwkUJGjKCHDlz2vuViTzQrJV7WPPHCc5FxnD5xp3H3wAM71yHYfN+s9y35o8TzFz5J289X8nw+1Yv5U2HxmXYvO882bI406NNZd6fv4UNu89w9Px1+oT8zL2EJLq2rABAAc9c7D95hb0nojgfdYvf9p1jfdgpuz6zyL9J5YxMqHK1GgwcNsryOmvWrADs/XMXSxd9xrkzp7lzJ5bk5GQS4uOJi7v7wBJEh05vMOXD0WxY/wPVatamUTN/8he4Pznz+JG/uBhxnl9Cf7S0N5shJSWFy5ciKFyk2CPH+FqX7qxd9S3r166icfMWVtf+7rtVQ+s5EwkJ8VyMuECZ2NvcuHGdMuUqWK45OjpSsnRZzGazwW9J5PH2Ho9KU3sPt6z4eeZi7sCWzH73n9/XTo4OxNx5dHDdqlYxrq55BydHB5wdHfhxx0kGzvmVoj65cXF2ZMfhi5a2Sckp/HksklJ+eQGY/2M4X498gcolvPh1z1l+2H6CsL8upWnskr5UzjBGQUQmlDVrtlQrMSIvX2Jo0Nu88FIHuvfuT65cbhzYv5cp40c9MBsA8GbPvjRr0Zodf2xl5/bfWfTZbEZNmEqDxs1IMafQ9qX2vNzx9VT3eXn7PHaMOXPmonPXt/ji87nUrd/Q6lqKOYWSpcvywfjJqe6zmiBq86fUjAIISV93bFZGpKSYUyWX/y45ADj85/dk3+k/s+voZat2ySmP/v25Zf95BszYSFJSCpeux1omcXq7ZwdIFSCbTP/8nt+w+wylAufRsmZRmlQtzPrJHZi3Npzh8zcb+pyS/hREGKNyxlPi2JHDJCcl0ydoCOUqVMKvUGGuX7362Pv8ChWmQ6c3+HjWfOo3bsZPP6wGoGSpspw9dYoCfgVTHc7OzobG9FKHzphMJr5bvtTqfMlSZYm4cI48edxT9Z0jR05y5MiJu3tejh4+aLknOTmZk8eOGv9CROxwLSYOr//8o/63isU8Lb++cvMuF6/eprBPbk5fuml1nIuMeWTfd+8lcvrSTc5fuWW1CuTUpZvEJyRRt3wByzknRweqlvDm2PkbVmNbuvEw3SavY8inv9Ht+Yr/7ceV/4IpHf97limIeEr45vcjOTmJlSuWcSniAj+vX8vald88tH38vXtMnzKBfXt2EXn5Egf37+XYX4coVKQoAJ26dOPwwf2ETP6QE8eOEnH+HH9s+Y3pUx8/sfJvrq6uvNmrL9+vWGZ1vnmr1rjlzsP7g/uzf98eLl+MIHzPbmZ8FMyVqPuz0V/q2Illiz9n25ZNnD97hpkfT+L2rVvaOk+eqK37z5PPLRuDOtSkiE9uerWtgn/1IlZtPlzyB0M61qJvu6oUz5+HcoU9CPQvz4CXq9v1nnfvJTL/x3Am9mhI8+qFKV0wL3PebUFWVycWhx4AYOQbz9GmTnGK+uamTKG8tKpVlGMXrv/Xn1fkSVM54ylRolRp+r77Hl99uZDPZn9CpSrV6NH3HSaOfv+B7R0cHYmJucnE0e8TfeM6brnzUL9xM97s2ReAYiVK8cm8RXw+dwb9e74BZjO+Bfxo3LxlmsbVsvULfLP0C86e+WcSWJYsWZkx7wvmzZrGyPeCiLt7B498nlStUZvs2XMA8Nob3bl+/ToTR7+Pg6MDbdu1p0ad53BwUFwrT86xCzd4Z+ZG3nutNsM612H1tuNM/2433f/fpMnFoQeJi08iqH0NJrzVkDv3Ejl89hqzVu2x+30/WLAVBwcTC95rTc5sLuw9HknA+99xM/b+PIuEpGTGdatPIS834hKS2H4ogsCJPz6mV3mSHPQDjSEmcyaZyRZ5S091+1+WkpLCG+0DaNysBd3f7p/Rw8k0irwyPaOHIJIpPe6Jpf+tTUfTLxPUpHTedOsrs9GPfZIhIi9f4odV33Hh3FlOnTzOtEnjuXwpgqYtn8/ooYmIZJitW7fStm1bfH19MZlMrF692up6165dMZlMVkft2rWt2sTHx9O/f388PDzInj07AQEBREREWLWJjo4mMDAQNzc33NzcCAwM5ObNm2ker4IIyRAOJhOhP66mV5dX6fdWIKdPHmfa7M8fu7RUROTfkFEbcN25c4dKlSoxa9ash7Zp2bIlly9fthzr16+3uh4UFMSqVatYvnw527ZtIzY2ljZt2pCcnGxp06lTJ8LDwwkNDSU0NJTw8HACAwPTNlg0J0IyiKe3D7MXLH18QxGRDJBRqypatWpFq1atHtnG1dUVb2/vB16LiYlhwYIFLFmyhGbNmgGwdOlS/Pz8+OWXX2jRogVHjhwhNDSUsLAwatWqBcD8+fOpU6cOx44do1SpUobHq0yEiIjIExQfH8+tW7esjsc9GfhRNm/ejKenJyVLlqRHjx5cuXLFcm3Pnj0kJibi7+9vOefr60v58uXZvn07ADt27MDNzc0SQADUrl0bNzc3SxujFESIiIjYcDCl3xEcHGyZe/D3ERwcbNe4WrVqxbJly9i0aRMff/wxu3fvpkmTJpagJDIyEhcXF/LY7Pzs5eVFZGSkpY2np2eqvj09PS1tjFI543/A3Tt3WPDpTH7f/CvR0TcoUbI0/QcNszx2+sb1a8ybGcLunduJvX2bSlWq8c6Q9ylQsJClj4SEBOZ88hGbfl5PfHw8VWvU4t2hH+Dp9eCUmkhm06NNZXq0qUwhr1wAHDl3nYnLtrNh9xmcHB0Y07UeLWoWpYiPG7fuJLBp7zlGLthi2XOjoFcuji3p9cC+O49fw8rfjwNw9MueFPJ2s7r+0fKdjFy49Ql+Oklv6VnOGD58OAMHDrQ65+rqaldfHTt2tPy6fPnyVK9enUKFCrFu3Tpeeumlh95nNpsx/b8JGqYHTNawbWOEgoj/AVM+HMWZUycZMTaYvPk82fjTDwzq24MvvlmDRz5PRgx5BycnJyZ8NIPs2XPwzVdfMrDvW3zxzRrLnhwzp01ix+9bGDVhKrly52bO9KkMf7cvny35BkdHxwz+hCKPd/HabUYu2MKpSzcBeL15Ob4d8yK1+3zBxau3qVzCi0nLdnDg9BXy5MjC1Leb8O24l6jXbwkAEVdvU7jjHKs+uz1fkYEdavLzbusdQsd+sY1F6w9YXsfGJTzZDyeZmqurq91Bw+P4+PhQqFAhTpw4AYC3tzcJCQlER0dbZSOuXLlC3bp1LW2iolLvK3P16lW8vLzS9P4qZzzj4u/dY+tvv9B7wEAqVa1OAb+CvNmzLz6++Vnz/Qoizp/jr4P7GTh0JGXKVaBg4SK8O/QD4uLu8uvP92f8xsbeZv2alfR5ZzDVa9WhZKkyfDBuEqdPnWDPrrAM/oQixqwPO8XPu89w8mI0Jy9GM2bxNmLjEqhZxpdbdxNoM+xbvt96jBMR0ew6epmBs3+lWklv/PLd3102JcVMVPQdqyPguRJ8t+Voqj06Yu8mWLWzvS6ZX0atzkir69evc+HCBXx87u95VK1aNZydndm4caOlzeXLlzl06JAliKhTpw4xMTHs2rXL0mbnzp3ExMRY2hilIOIZl5ycTHJyMi4u1lGwS5YsHAzfS0Li/Z+QXFxdLNccHR1xcnLmYPg+4P6unElJSdSo/c9vLo98nhQpVpxDB/b9C59CJH05OJho36g02bM4s/Mhu2Xmyu5KSoqZmw/ZvbNKCS8qF/fii9CDqa4N7FCTiO/6ETa3C++9Vttqky95OpjS8UiL2NhYwsPDCQ8PB+DMmTOEh4dz/vx5YmNjGTx4MDt27ODs2bNs3ryZtm3b4uHhwYsvvgiAm5sb3bt3Z9CgQfz666/s27eP119/nQoVKlhWa5QpU4aWLVvSo0cPwsLCCAsLo0ePHrRp0yZNKzNA5YxnXrbs2SlXoRJfLviUQkWKksc9L7/+vJ4jhw5QwK8QhQoXwdvHl89mf8Lg4aPIkjUb3yz7ghvXr3H9+v0Nvq5fv4azszM5c1nXefO45+XGdT3fX54e5Qp7sPmTzmRxcSI2LoGOY1dz9Hzq38Ouzo6M796AFb8d4fbdB5ciurSswJFz11Jt2T179R72nYjiZmw81Ut5M65bAwp7u9En5Ocn8pnkyXB40imEh/jzzz9p3Lix5fXfcym6dOnC3LlzOXjwIF9++SU3b97Ex8eHxo0bs2LFCnLmzGm5JyQkBCcnJzp06EBcXBxNmzZl8eLFVqXnZcuWMWDAAMsqjoCAgEc+m+Jh0j2IuHDhAqNHj2bhwoUPbRMfH59qeUt8vMMTqxn9rxsxLpjJ40bx8vNNcHR0pESpMjRr8TzHjx3BycmZcZNDmDJ+FG2aPoejoyPVatSmVt36j+33/iScf+EDiKST4xE3qPX2F+TO7kq7+iWZP+R5/AcvtwoknBwdWDKiLQ4mE+/M3PjAfrK4ONGxcRkmLduR6trMlf/ssXHozFVuxsbz9agX+ODzLdy4fS/9P5Q8Uxo1apRq2/j/7+efHx+MZsmShZkzZzJz5syHtnF3d2fp0v/+WT3pnmO7ceMGX3zxxSPbPGi5y8xpk9N7KPIf+QsUZMZniwnduotvf/yFeV8sJykpCR/f/ACUKlOOBV99z7rfdrDyp9+YOnMet2JuWq7nzetBYmIit29Zb4V8M/oGedyf3WfCy7MnMSmF05dusvdEFKMW/s7B01fp+2I1y3UnRweWfRBAIS832gz75qFZiBfrlySbqzPLfjn82PfcdeR+pqJY/jyPaSmZSUaVM542ac5ErF279pHXT58+/dg+HrTcJTpeNcMnLWvWbGTNmo3bt2LYHbadXv2t/x/kyHE/HRZx/hzHjhyme+9+AJQsUxYnJyd279xBk//s8nn92lXOnDpJ7/6D/t0PIZKOTKb7pQv4J4Aolj83LYeseGTWoGvLCqwLO8m1mLjHvkel4vfX40dej02fQcu/41n/1z+dpDmIaNeuHSaT6ZHplsetM33Qcpe72sXzidm14w/MZjMFCxUmIuI8n37yMX6FCvN8QDsAfvvlZ3LnyYOXlw+nT51g5seTqNewCTVqPwfcDy6ef+El5kyfiptbbnK6uTF3+kcULVaCajVrP+KdRTKPsW/WZ8Pu01y4epucWV1o36g0DSr6ETDiOxwdTHw1MoAqJbx4aeRKHB0c8MqTHYAbt+NITEqx9FPUNzf1KvjR7oPvUr1HrTK+1Czjw5bwC8Tcjad6SW+m9G7MD9tPcOHq7X/ts4r8W9IcRPj4+DB79mzatWv3wOvh4eFUq1btgdckY8TG3mb+7OlcvRJFzlxuNGzSnLf6DMDJyRm4n1WYHTKF6BvXyeuRjxbPB/DGW72t+uj37lAcHZ0Y8/4g4u/df9hU8OhZekaEPDU882RjwXut8XbPTszdeA6dvkbAiO/YtPccBb1y0bZuCQB2fdrV6j7/wcv5/cAFy+suLSpw6fptftlzNtV7xCcm8UrD0rz/el1cnR05f+UWC386wLRvdqVqK5lbRu2d8bQxmR+VUniAgIAAKleuzLhx4x54ff/+/VSpUoWUlJQHXn+YSGUiRFIp8sr0jB6CSKYUt2HIE+1/1+mYxzcyqGZRt8c3ekqlORMxZMgQ7ty589DrxYsX57fffvuvBiUiIiKZX5qDiPr1H730L3v27DRs2NDuAYmIiGQ0FTOM0cOmREREbCmKMETrKkVERMQuykSIiIjY0OoMY5SJeMrs3/snw97ty0utGtOwRnl+3/yr1fWtmzYyuH9PAprVo2GN8pw4dtRQv7dv3yJk8oe82LIRzZ+rSmD7toT9sdXw+wIsX7KIdi0a0K5FA7756kura38dOkCPwA4kJyfb8alFHq1Hm8rs+rQrUasGELVqAJund8a/RhHL9exZnAnp25STy3pz44cg9n3ejR5tKj+yzxeeK8G2WYFcXtmfa2vfIWxuF15rWtaqTY6szkzt3ZhjS3py44cgfgvpRLWS3lZtgl6pwdkVfTi7og/9X7Je/l6jtA9/zA7EwUH/YGU2T8sunhlNmYinTFxcHMVLluL5tu0YOfTd1NfvxVG+YhUaNfVn6oQxhvpMTExkUN8e5HF3Z9zkaeTz9OZKVCTZsmUz/L6nTh5n4bzZTAqZjdlsZtjAvlSvWYeixUuQlJTIx8HjGPz+aD1XQp6Ii9duM3LBFk5dugnA683L8e2YF6nd5wuOnLvOlN6NaVipIG9OXse5qBiaVSvMJ/2bc/l6LD/uOPnAPm/cvseUr8M4dv46CUkpPF+rKJ8NbsXVm3ctz4iY+25Lyhb2oNuU9Vy+HstrTcuybnIHqr61kEvXYylX2IORbzzHS6NWYgJWjn+JX/ee46+z13BydGDGgOb0m76BlJQ0rbSXf8Ez/m9/ulEQ8ZSp/Vx9aj/38BUyLZ4PAODypYuG+1y/diW3b8UwZ+FSywOovH180/S+586cpliJklStUQuAYsVLcu7saYoWL8HXSxZRqUo1ypSrYHhMImmxPuyU1esxi7fRo01lapbx5ci569Qq68vSXw5bHhq1cP0BureuRNWSXg8NIv7/A6YAZq/eS+fm5albPj+/7DlLFhcn2tUvSfvRq/jjYAQAE5Zsp23dEvRoW5mxi7dRumBeDp25ypbw88D9DblK+7nz19lrvNu+Bn8cjGDP8cj0/jpE/jUqZwh/bN1MuQqVCJk8gXYtGtC1YzuWLPosTaWHosVLcOH8WaIiLxN5+RIXzp+jSLHiRFw4T+iPa3jr7QFP8BOI/MPBwUT7RqXJnsWZnf/Zpnv7oYu0qV0M37w5AGhQyY8S+d355c+zhvttVLkgJf3ysO0/AYOTowknRwfuJSRZtbsXn0Tdcvc3rzt05irF8+fBL19OCnrmonh+dw6fvUZR39wE+pdnzOLf0+ETyxOhHbgMUSZCuHwxgn1/XqRZy9ZMnj6XiAvnmD5lAslJyXTt8bahPgoXKUaPPu8wqG8PAHr2fYfCRYoxsM9b9O4/kF1hf7D4szk4OjkxYNAwKlWt/iQ/kvwPKlfYg82fdCaLixOxcQl0HLvassX3oDm/MufdFpz6+m0Sk5JJSTHzdsjPbD/86IxdrmwunPr6bVydHUlOMfPOzI1s2nsOgNi4RMIOX2R45zocO3+dqJt36dC4DDVK+3DyYjQAxy7cYPSi3/lxUgcARi3cyrELN1g3qQMjPt9C8+pFGBFYl8SkFAbP3WTJaEjG08RKYxRECCnmFHLncWfw+2NwdHSkVJlyXLt6leVLFhkOIgBeeLkjL7zc0fL6px9WkzV7NspVqETgK22Z98VyrlyJYuyIISxf8zMuLi5P4uPI/6jjETeo9fYX5M7uSrv6JZk/5Hn8By/n6Pnr9G1XjZqlfXl51ErOR92iXoUCfNK/OZE37vDbvnMP7fN2XAK13v6CHFlcaFylIJN7NebM5RhLqaPblPXMG9SS08v7kJScQviJKFb8doTK/9m5E+Dzdfv5fN1+y+vXm5cjNi6BnX9dYv/C7tTrt4T8+XKy5P22lH7jMxISNflYnh4KIoS8efPh5ORkNemxUOGi3Lh+jcTERJydndPc582b0Xzx+afM+GwxRw4dpEDBQpYjKSmJC+fPUqx4yfT8GPI/LjEphdP/mVi590QU1Ur60PfFagyZu4mxb9an49jVhO46DdwvM1Qs5knQKzUeGUSYzVj6PHD6CqUK5mXIq7UsQcSZyzfxH7ycbFmcyZXNhcgbd1jyflvORj5434W8ubLy/ut1aT7o6/sZi4hoTl26yalLN3FydKBE/jwcPnst/b4UsduzvqoivWhOhFC+UmUuRpy32jQt4vxZ8nrksyuAAJj18STadwrE08ub5JRkkpL+qRsnJyeTkpy2DdpE0spkAldnR5ydHHBxdiTFZq/B5BRzmpdW/t2nrbv3Eom8cYfcOVxpVr3wQydrTn27CTNX/snFa7E4Ojrg5PTPX8FOjg44Ouiv5MxCUyKMUSbiKXP37l0uXjhveX350kVOHDtKLjc3vLx9uBUTQ1TkZa5fuwLAhXNnAHDP60FeDw8AJoweTr58nvTsd3+pZruXO7Lym6+Y8fEkXu7QiYgL51i6eD4vd+xs+H3/v907txNx4Tzvjw0GoEy5Cpw/d4awP37nSlQkjg4OFCxUOP2/HPmfNfbN+mzYfZoLV2+TM6sL7RuVpkFFPwJGfMftuwls3X+eiT0aEhefxPkrt6hfoQCdm5Vl6LzNlj4+H/I8l67fZtTC+5MdB79ai73HIzl96SYuzo60rFmUzs3KMWDGRss9zaoVxmSC4xHRFPPNzcQejTgRcYMvfz6UaoxNqhaieP7cdJ+yDoA/j16mlJ87/jWKUCBfTpJTUjgecePJflEi6UxBxFPm2JFDBPXuZnk9O2QKAC1bv8DwMRP4Y+tvTBr3geX62BH3t8vt2uNt3uzZF4ArkZdxMP3zE4+ntw8fzfyM2SFT6NbpJTzyefLyq6/T6Y3uht/3b/H37vHJlImMnvgRDv/5qSqfpxfvDB7O5HEf4OziwvAxE3DNkiXdvhMRzzzZWPBea7zdsxNzN55Dp68RMOI7yyTINyb+yLhu9Vk8rDV5cmbh/JVbjFm8jfk/hlv68PPMaZWtyJ7FmU/6Nye/Rw7i4pM4fuEG3Sav47stxyxt3LK7Mq5bA/J75ODG7Xus2Xac0Yt+J8km05bFxYmQvs0InPADf7/FpeuxDJz9K/MGtSIhMYkeU39KtdJDMtCznkJIJyaz2ZwpnnISeSsxo4cgkukUeWV6Rg9BJFOK2zDkifZ/4EJsuvVV0S9HuvWV2agAJyIiInZROUNERMSGVmcYoyBCRETEhmIIYxREiIiI2FIUYYjmRIiIiIhdlIkQERGxob0zjFEQISIiYkMTK41ROUNERETsokyEiIiIDSUijFEQISIiYktRhCEqZ4iIiIhdlIkQERGxodUZxiiIEBERsaHVGcaonCEiIiJ2USZCRETEhhIRxiiIEBERsaUowhAFESIiIjY0sdIYzYkQERERuygTISIiYkOrM4xRECEiImJDMYQxKmeIiIiIXZSJEBERsaVUhCEKIkRERGxodYYxKmeIiIiIXZSJEBERsaHVGcYoiBAREbGhGMIYlTNERETELspEiIiI2FIqwhAFESIiIja0OsMYBREiIiI2NLHSGM2JEBEREbsoEyEiImJDiQhjFESIiIjYUDnDGJUzRERExC7KRIiIiKSiVIQRykSIiIjYMJnS70iLrVu30rZtW3x9fTGZTKxevdrqutlsZsyYMfj6+pI1a1YaNWrE4cOHrdrEx8fTv39/PDw8yJ49OwEBAURERFi1iY6OJjAwEDc3N9zc3AgMDOTmzZtp/p4URIiIiGQSd+7coVKlSsyaNeuB16dMmcK0adOYNWsWu3fvxtvbm+bNm3P79m1Lm6CgIFatWsXy5cvZtm0bsbGxtGnThuTkZEubTp06ER4eTmhoKKGhoYSHhxMYGJjm8ZrMZrM57R8z/UXeSszoIYhkOkVemZ7RQxDJlOI2DHmi/V+6mZBuffnmdrHrPpPJxKpVq2jXrh1wPwvh6+tLUFAQQ4cOBe5nHby8vJg8eTK9evUiJiaGfPnysWTJEjp27AjApUuX8PPzY/369bRo0YIjR45QtmxZwsLCqFWrFgBhYWHUqVOHo0ePUqpUKcNjVCZCRETERkaVMx7lzJkzREZG4u/vbznn6upKw4YN2b59OwB79uwhMTHRqo2vry/ly5e3tNmxYwdubm6WAAKgdu3auLm5WdoYpYmVIiIiT1B8fDzx8fFW51xdXXF1dU1TP5GRkQB4eXlZnffy8uLcuXOWNi4uLuTJkydVm7/vj4yMxNPTM1X/np6eljZGKRMhIiJiw5SO/wUHB1smMP59BAcH2z82m/SG2WxOdc6WbZsHtTfSjy0FESIiIrZM6XcMHz6cmJgYq2P48OFpHpK3tzdAqmzBlStXLNkJb29vEhISiI6OfmSbqKioVP1fvXo1VZbjcRREiIiI2EjHGAJXV1dy5cpldaS1lAFQpEgRvL292bhxo+VcQkICW7ZsoW7dugBUq1YNZ2dnqzaXL1/m0KFDljZ16tQhJiaGXbt2Wdrs3LmTmJgYSxujNCdCREQkk4iNjeXkyZOW12fOnCE8PBx3d3cKFixIUFAQEydOpESJEpQoUYKJEyeSLVs2OnXqBICbmxvdu3dn0KBB5M2bF3d3dwYPHkyFChVo1qwZAGXKlKFly5b06NGDefPmAdCzZ0/atGmTppUZoCBCREQklYzaO+PPP/+kcePGltcDBw4EoEuXLixevJj33nuPuLg4+vTpQ3R0NLVq1WLDhg3kzJnTck9ISAhOTk506NCBuLg4mjZtyuLFi3F0dLS0WbZsGQMGDLCs4ggICHjosykeRc+JEMnE9JwIkQd70s+JuHo7Kd36ypfz2f15XXMiRERExC7PbngkIiJiL+2/ZYiCCBERERuKIYxROUNERETsokyEiIiIjYxanfG0URAhIiJiw6SChiEqZ4iIiIhdlIkQERGxoXKGMcpEiIiIiF2UiRAREbGhTIQxykSIiIiIXZSJEBERsaHVGcYoiBAREbGhcoYxKmeIiIiIXZSJEBERsaFEhDEKIkRERGwpijBE5QwRERGxizIRIiIiNrQ6wxgFESIiIja0OsMYlTNERETELspEiIiI2FAiwhgFESIiIrYURRiiIEJERMSGJlYaozkRIiIiYhdlIkRERGxodYYxJrPZbM7oQUjmER8fT3BwMMOHD8fV1TWjhyOSKejPhciDKYgQK7du3cLNzY2YmBhy5cqV0cMRyRT050LkwTQnQkREROyiIEJERETsoiBCRERE7KIgQqy4uroyevRoTR4T+X/050LkwTSxUkREROyiTISIiIjYRUGEiIiI2EVBhIiIiNhFQYSIiIjYRUGEWMyZM4ciRYqQJUsWqlWrxu+//57RQxLJUFu3bqVt27b4+vpiMplYvXp1Rg9JJFNRECEArFixgqCgIEaMGMG+ffuoX78+rVq14vz58xk9NJEMc+fOHSpVqsSsWbMyeigimZKWeAoAtWrVomrVqsydO9dyrkyZMrRr147g4OAMHJlI5mAymVi1ahXt2rXL6KGIZBrKRAgJCQns2bMHf39/q/P+/v5s3749g0YlIiKZnYII4dq1ayQnJ+Pl5WV13svLi8jIyAwalYiIZHYKIsTCZDJZvTabzanOiYiI/E1BhODh4YGjo2OqrMOVK1dSZSdERET+piBCcHFxoVq1amzcuNHq/MaNG6lbt24GjUpERDI7p4wegGQOAwcOJDAwkOrVq1OnTh0+++wzzp8/T+/evTN6aCIZJjY2lpMnT1penzlzhvDwcNzd3SlYsGAGjkwkc9AST7GYM2cOU6ZM4fLly5QvX56QkBAaNGiQ0cMSyTCbN2+mcePGqc536dKFxYsX//sDEslkFESIiIiIXTQnQkREROyiIEJERETsoiBCRERE7KIgQkREROyiIEJERETsoiBCRERE7KIgQkREROyiIEJERETsoiBCRERE7KIgQkREROyiIEJERETsoiBCRERE7PJ/xQuYMPmsxmYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign labels\n",
    "y_true = train_df['label']\n",
    "y_pred = roberta['roberta_labels']\n",
    "\n",
    "# Classification metrics\n",
    "accuracy = round(accuracy_score(y_true, y_pred), 4)\n",
    "precision = round(precision_score(y_true, y_pred), 4)\n",
    "recall = round(recall_score(y_true, y_pred), 4)\n",
    "f1 = round(f1_score(y_true, y_pred), 4)\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred), 4)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Confusion matrix\n",
    "group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(conf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TznOh7_KWtB"
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Xhz9IlPwKWtB"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer\n",
    "from keras.layers import (\n",
    "        Dense,\n",
    "        Flatten,\n",
    "        InputLayer,\n",
    "        BatchNormalization,\n",
    "        Dropout,\n",
    "        Input,\n",
    "        LayerNormalization)\n",
    "from keras.losses import (\n",
    "        BinaryCrossentropy,\n",
    "        CategoricalCrossentropy,\n",
    "        SparseCategoricalCrossentropy)\n",
    "from keras.metrics import (\n",
    "    Accuracy,\n",
    "    TopKCategoricalAccuracy,\n",
    "    CategoricalAccuracy,\n",
    "    SparseCategoricalAccuracy)\n",
    "from keras.optimizers import Adam\n",
    "# from google.colab import drive\n",
    "# from google.colab import files\n",
    "from transformers import BertTokenizerFast, TFBertForSequenceClassification\n",
    "# (\n",
    "#     BertTokenizerFast,\n",
    "#     TFBertTokenizer,\n",
    "#     BertTokenizer,\n",
    "#     RobertaTokenizerFast,\n",
    "#     DataCollatorWithPadding,\n",
    "#     TFRobertaForSequenceClassification,\n",
    "#     TFBertForSequenceClassification,\n",
    "#     TFBertModel,\n",
    "#     create_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fEipHHSyKWtB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anaqi_Amir/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and tokernizer\n",
    "MODEL=\"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TFttJxTTKWtB"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e0ca282dca40489a471dfbb923b346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to tokenize text in data\n",
    "def preprocess_function(data):\n",
    "  return tokenizer(data[\"text\"],padding=True,truncation=True)\n",
    "\n",
    "# Tokenizing train data\n",
    "tokenized_dataset = train_data.map(preprocess_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NxHhFiMoKWtI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1996, 2600, 2003, 16036, 2000, 2022, 199...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1996, 9882, 2135, 9603, 13633, 1997, 100...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 4621, 2021, 2205, 1011, 8915, 23267, 160...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2065, 2017, 2823, 2066, 2000, 2175, 2000...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 19391, 2004, 2242, 4678, 1010, 2019, 327...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  the rock is destined to be the 21st century's ...      1   \n",
       "1  the gorgeously elaborate continuation of \" the...      1   \n",
       "2                     effective but too-tepid biopic      1   \n",
       "3  if you sometimes like to go to the movies to h...      1   \n",
       "4  emerges as something rare , an issue movie tha...      1   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 1996, 2600, 2003, 16036, 2000, 2022, 199...   \n",
       "1  [101, 1996, 9882, 2135, 9603, 13633, 1997, 100...   \n",
       "2  [101, 4621, 2021, 2205, 1011, 8915, 23267, 160...   \n",
       "3  [101, 2065, 2017, 2823, 2066, 2000, 2175, 2000...   \n",
       "4  [101, 19391, 2004, 2242, 4678, 1010, 2019, 327...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize tokenized_dataset\n",
    "pd.DataFrame({\n",
    "    'text':tokenized_dataset[:5]['text'],\n",
    "    'label':tokenized_dataset[:5]['label'],\n",
    "    'input_ids':tokenized_dataset[:5]['input_ids'],\n",
    "    'token_type_ids':tokenized_dataset[:5]['token_type_ids'],\n",
    "    'attention_mask':tokenized_dataset[:5]['attention_mask']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yycZxz4oKWtI"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# Padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "# Convert to tensorflow formatted df\n",
    "tf_train_dataset = tokenized_dataset.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"],\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "K2difbXeK8tw"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "in user code:\n\n    File \"/var/folders/5q/n8ssmgtj6nd825347vg7wz240000gn/T/ipykernel_71736/404505314.py\", line 3, in swap_positions  *\n        return {'input_ids':dataset['input_ids'],\n\n    KeyError: 'label'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m:dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m:dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m           } , dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tf_train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf_train_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswap_positions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2311\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rotten_tomatoes/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "File \u001b[0;32m/var/folders/5q/n8ssmgtj6nd825347vg7wz240000gn/T/__autograph_generated_filexlwwqzdy.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__swap_positions\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(dataset)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(dataset)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: ag__\u001b[38;5;241m.\u001b[39mld(dataset)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]}, \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: in user code:\n\n    File \"/var/folders/5q/n8ssmgtj6nd825347vg7wz240000gn/T/ipykernel_71736/404505314.py\", line 3, in swap_positions  *\n        return {'input_ids':dataset['input_ids'],\n\n    KeyError: 'label'\n"
     ]
    }
   ],
   "source": [
    "# Reformat dataset\n",
    "def swap_positions(dataset):\n",
    "  return {'input_ids':dataset['input_ids'],\n",
    "          'token_type_ids':dataset['token_type_ids'],\n",
    "          'attention_mask':dataset['attention_mask']\n",
    "          } , dataset['label']\n",
    "\n",
    "# Execution\n",
    "tf_train_dataset = tf_train_dataset.map(swap_positions).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dDGBRNUwLKAU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(8, 73), dtype=int64, numpy=\n",
      "array([[  101,  1037,  2843,  1997,  4569,  1010,  2007,  2019,  6151,\n",
      "        19825,  3468,  2943, 13977,  2011,  2048, 19910,  1999,  2037,\n",
      "         2753,  2015,  2551,  2012,  1996,  4672,  1997,  2037,  4204,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1037, 17743,  2176,  2086,  1999,  1996,  2437,  1012,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1037,  1005,  3057,  2908,  3748,  1005,  2678,  2005,\n",
      "         1996,  8945,  6806,  2396,  1011,  2160,  4306,  1010,  1996,\n",
      "         5255,  8742,  3475,  1005,  1056,  1037, 15764,  4675,  1011,\n",
      "         3451,  6254,  1011,  1011,  2049, 11153,  4995,  1005,  1056,\n",
      "         3718,  1998,  1999, 15549, 28032,  3512,  2438,  2005,  2008,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1031, 27996,  1033,  1998,  2522,  1011,  4898,  7059,\n",
      "         8670,  4143,  5280,  2050,  1998,  4519,  3536,  4232,  2031,\n",
      "        13538,  2205,  2172,  2006,  4680,  1999,  4526,  1996,  3494,\n",
      "         2040, 15161, 12784,  1012,   102,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2065,  1996,  2516,  2003,  1037, 26604,  3160,  1010,\n",
      "         2059,  1996,  3437,  2453,  2022,  1000,  2129,  2515,  7112,\n",
      "         2712,  9692,  2272,  2408,  2122,  2420,  1029,  1000,  2030,\n",
      "         2672,  1000,  2129,  2097,  2017,  2514,  2044,  2019,  6070,\n",
      "         1011,  3371, 10973,  1011,  2125,  1997,  1996,  2600,  2007,\n",
      "         2895, 12302,  2000, 22889,  2080,  1011,  9587,  3282,  7493,\n",
      "         1998,  6721,  3221,  1011, 21797,  1029,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  2009,  2987,  1005,  1056,  2393,  2008,  1996,  2472,\n",
      "         1998, 19245,  4459, 10556,  2480,  9856, 27472,  2072,  5607,\n",
      "         2006, 24665,  5575,  2100,  2678,  1010,  3228,  1996,  2878,\n",
      "         2518,  1037,  6530,  1010,  5510,  3238,  2514,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1037, 11382,  7096,  2098,  4027,  2003,  2019,  4895,\n",
      "        21678,  2989,  4356,  1010,  1998, 24668,  1997,  2010,  1010,\n",
      "         2065,  2017,  2097,  1010,  2041,  1011,  1997,  1011, 11382,\n",
      "        21928,  2839,  1010,  2040,  8223, 13510,  6614, 10895,  2083,\n",
      "         5665,  1011, 10141,  2895,  4109,  1012,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0],\n",
      "       [  101,  1037,  8403,  2143,  2005,  1996,  6209,  2161,  1012,\n",
      "          102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0]])>, 'token_type_ids': <tf.Tensor: shape=(8, 73), dtype=int64, numpy=\n",
      "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(8, 73), dtype=int64, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0]])>, 'labels': <tf.Tensor: shape=(8,), dtype=int64, numpy=array([1, 1, 0, 0, 0, 0, 0, 1])>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:21:52.284057: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Check\n",
    "for i in tf_train_dataset.take(1):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "vxxgPmhlOVpe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109483778 (417.65 MB)\n",
      "Trainable params: 109483778 (417.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "MyWlcxacQgKO"
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "num_epochs = 3\n",
    "batches_per_epoch = len(tokenized_dataset) // 8\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "# Optimizer\n",
    "# optimizer, schedule = create_optimizer(init_lr=2e-5,\n",
    "#                                        num_warmup_steps=0,\n",
    "#                                        num_train_steps=total_train_steps)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    weight_decay=None,\n",
    "    clipnorm=None,\n",
    "    clipvalue=None,\n",
    "    global_clipnorm=None,\n",
    "    use_ema=False,\n",
    "    ema_momentum=0.99,\n",
    "    ema_overwrite_frequency=None,\n",
    "    name='adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kvhPyM0PSVu-"
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fTe-FtJZSlzs"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6812acd49ebe4318932839cb0929c288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prep testing set\n",
    "\n",
    "# Tokenizing train data\n",
    "tokenized_test_dataset = test_data.map(preprocess_function, batched=True)\n",
    "\n",
    "# Convert to tensorflow formatted df\n",
    "tf_test_dataset = tokenized_test_dataset.to_tf_dataset(\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"label\"],\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Swap column positions\n",
    "#tf_test_dataset = tf_test_dataset.map(swap_positions).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySEcusENSgEl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# # initialize tqdm callback with default parameters\n",
    "# tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "\n",
    "# Model training with TQDM progress bar\n",
    "history = model.fit(\n",
    "    tf_train_dataset.take(1000),\n",
    "    validation_data=tf_test_dataset,\n",
    "    epochs=3,\n",
    "    verbose = 100\n",
    "    # callback = tqdm_callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUThmAFfeDVk"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McKRNemKeIRX"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
